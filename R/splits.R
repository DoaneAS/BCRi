



#' Takes a db, a cloneID, and the name of a phenotype variable and returns the affinity matrix, db, and data.frame of per-phenotype diversity metrics for that clone
#'
#' @param db db
#' @param cloneID ID of clone to analyze
#' @param phenotype_var phenotype variable
#' @param cell_id cell id
#' @param clone column name of clone variable in db
#' @param log_base base of log to use for shannon entropy calculations
#' @export
#' @returns data.frame of diversity metrics and phenotype ##list with affinity matrix, db for clone, and data.frame of per-phenotype diversity metrics using Simposon diversity
weighted_diversity_splits <- function(db, grpID=NULL, phenotype_var="subset", cell_id=NULL,
                               grp = "subject_id", cdr3=FALSE, useAffinityWeights=TRUE,similarity=TRUE,
                               log_base=exp(1), distanceCutoff=FALSE, discreteVar="clone_id") {
  model = "spectral"
  method = "vj"
  linkage = c("single", "average", "complete")
  normalize = "len" ## c("len", "none"),
  germline = "germline_alignment"
  sequence = "sequence_alignment"
  junction = "junction"
  v_call = "v_call"
  j_call = "j_call"
  fields = NULL
  locus = "locus"
  only_heavy = TRUE
  split_light = FALSE
  targeting_model = shazam::HH_S5F
  len_limit = NULL
  first = FALSE
  #cdr3 = FALSE
  mod3 = FALSE
  max_n = 0
  threshold = 1
  base_sim = 0.95
  iter_max = 1000
  nstart = 1000
  nproc = 4
  verbose = FALSE
  log = NULL
  summarize_clones = FALSE
  indVar = "ind"


  process_subset <- function(db_subset) {
    results_prep = prepare_clone(db = db_subset,
                                 junction = junction, v_call = v_call, j_call = j_call,
                                 first = first, cdr3 = cdr3, fields = fields,
                                 cell_id = cell_id, locus = locus, only_heavy = only_heavy,
                                 mod3 = mod3, max_n = max_n)
    db <- results_prep$db
    n_rmv_mod3 <- results_prep$n_rmv_mod3
    n_rmv_cdr3 <- results_prep$n_rmv_cdr3
    n_rmv_N <- results_prep$n_rmv_N
    junction_l <- results_prep$junction_l
    cdr3_col <-  results_prep$cdr3_col

    db_l <- db[db[[locus]] %in% c("IGK", "IGL", "TRA", "TRG"), , drop=F]
    db <- db[db[[locus]] %in% c("IGH", "TRB", "TRD"), , drop=F]
    db_gp <- db

    mutabs <- shazam::HH_S5F@mutability
    # Generated by using Rcpp::compileAttributes() -> do not edit by hand
    # Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

    #Rcpp::sourceCpp("~/Projects/code/scratch/scoper/src/RcppMutation.cpp") # scoper/src/RcppMutation.cpp")
    #Rcpp::sourceCpp("./src/RcppMutation.cpp")

    n <- nrow(db_gp)


    germs <- db_gp[[germline]]
    seqs <- db_gp[[sequence]]
    ## accomdate different length sequences for hamming distance
    juncs <- db_gp[[ifelse(cdr3, cdr3_col, junction)]]
    #juncs <- as.character( set_eq_seqDistance(juncs))
    junc_length <- unique(stringi::stri_length(juncs))
    if (length(junc_length) > 1) {
      juncs <- as.character( set_eq_seqDistance(juncs))
      junc_length <- unique(stringi::stri_length(juncs))
    }


    #juncs <- as.character( set_eq_seqDistance(juncs))
    # find unique seqs
    #.I = NULL
    seqs <- paste(seqs, juncs, germs, sep = "|")
    df <- data.table::as.data.table(seqs)[, list(list(.I)), by=seqs] %>%
      tidyr::separate(col = seqs, into = c("seqs_unq", "juncs_unq", "germs_unq"), sep = "\\|")
    n_unq <- nrow(df)
    ind_unq <- df$V1

    ## make result df here

    if (n_unq <= 2) {

      mtxx = matrix(0, n_unq, n_unq)
      diag(mtxx) <- 1
      db_gp$subsetInd <- rep(NA, nrow(db_gp))

      for (i in 1:n_unq) {
        #idCluster[ind_unq[[i]]] <- idCluster_unq[i]
        db_gp$subsetInd[ind_unq[[i]]] <- i
      }

      return_list <- list("mtx" = mtxx,
                  "db" = db_gp,
                  "subsetInd" = ind_unq)

      return(return_list)

    } else{

      # find corresponding unique germs and junctions
      seqs_unq <- df$seqs_unq
      germs_unq <- df$germs_unq
      juncs_unq <- df$juncs_unq
      # calculate unique junctions distance matrix
      dist_mtx <- alakazam::pairwiseDist(seq = juncs_unq,
                                         dist_mat = getDNAMatrix(gap = 0))
      # count mutations from unique sequence imgt
      results <- pairwiseMutions(germ_imgt = germs_unq,
                                 seq_imgt = seqs_unq,
                                 junc_length = junc_length,
                                 len_limit = len_limit,
                                 cdr3 = cdr3,
                                 mutabs = mutabs)
      tot_mtx <- results$pairWiseTotalMut
      sh_mtx <- results$pairWiseSharedMut
      mutab_mtx <- results$pairWiseMutability
      # calculate likelihhod matrix
      lkl_mtx <- likelihoods(tot_mtx = tot_mtx,
                             sh_mtx = sh_mtx,
                             mutab_mtx = mutab_mtx)
      # calculate weighted matrix
      disim_mtx <- dist_mtx * (1.0 - lkl_mtx)


      mtx = disim_mtx

      nearest_dist <- apply(mtx, 2,  function(x) {
        gt0 <- which(x > 0)
        if (length(gt0) != 0) { min(x[gt0]) } else { NA }
      })


      krnl_mtx <- krnlMtxGenerator(mtx = mtx)


      if (distanceCutoff) {
        aff_mtx <- makeAffinity(mtx_o = mtx,
                                mtx_k = krnl_mtx,
                                thd = max(nearest_dist, na.rm = T))
        #aff_mtx[aff_mtx > max(nearest_dist, na.rm = T)] <- 0
      } else {
        aff_mtx <- krnl_mtx
      }

      db_gp$subsetInd <- rep(NA, nrow(db_gp))

      for (i in 1:n_unq) {
        #idCluster[ind_unq[[i]]] <- idCluster_unq[i]
        db_gp$subsetInd[ind_unq[[i]]] <- i
      }

      return_list <- list("mtx" = aff_mtx,
                  "db" = db_gp,
                  "subsetInd" = ind_unq)

      return(return_list)
    }
  }


  # get clone
  print(grpID)
  db_grp <- as.data.frame(db[db[[grp]] == grpID, ])
  results_prep = prepare_clone(db = db_grp,
                               junction = junction, v_call = v_call, j_call = j_call,
                               first = first, cdr3 = cdr3, fields = fields,
                               cell_id = cell_id, locus = locus, only_heavy = only_heavy,
                               mod3 = mod3, max_n = max_n)
  dbfull = data.table::copy(db)
  db <- results_prep$db
  n_rmv_mod3 <- results_prep$n_rmv_mod3
  n_rmv_cdr3 <- results_prep$n_rmv_cdr3
  n_rmv_N <- results_prep$n_rmv_N
  junction_l <- results_prep$junction_l
  cdr3_col <-  results_prep$cdr3_col

  db_l <- db[db[[locus]] %in% c("IGK", "IGL", "TRA", "TRG"), , drop=F]
  db <- db[db[[locus]] %in% c("IGH", "TRB", "TRD"), , drop=F]
  db_gp <- db

  mutabs <- shazam::HH_S5F@mutability
  # Generated by using Rcpp::compileAttributes() -> do not edit by hand
  # Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

  #Rcpp::sourceCpp("~/Projects/code/scratch/scoper/src/RcppMutation.cpp") # scoper/src/RcppMutation.cpp")
  #Rcpp::sourceCpp("./src/RcppMutation.cpp")

  n <- nrow(db_gp)


  germs <- db_gp[[germline]]
  seqs <- db_gp[[sequence]]
  ## accomdate different length sequences for hamming distance
  juncs <- db_gp[[ifelse(cdr3, cdr3_col, junction)]]
  #juncs <- as.character( set_eq_seqDistance(juncs))
  junc_length <- unique(stringi::stri_length(juncs))
  if (length(junc_length) > 1) {
    juncs <- as.character( set_eq_seqDistance(juncs))
    junc_length <- unique(stringi::stri_length(juncs))
  }


  #juncs <- as.character( set_eq_seqDistance(juncs))
  # find unique seqs
  #.I = NULL
  seqs <- paste(seqs, juncs, germs, sep = "|")
  df <- data.table::as.data.table(seqs)[, list(list(.I)), by=seqs] %>%
    tidyr::separate(col = seqs, into = c("seqs_unq", "juncs_unq", "germs_unq"), sep = "\\|")
  n_unq <- nrow(df)
  ind_unq <- df$V1


  sim_mtx = matrix(0, n_unq, n_unq)
  diag(sim_mtx) <- 1




  ## make result df here
  dgc = data.frame(pheno = unique(db_gp[[phenotype_var]]))
  dgc[[phenotype_var]] = unique(db_gp[[phenotype_var]])
  #dgc[[phenotype_var]] = unique(db_gp[[phenotype_var]])
  dgc$rgsw = 0
  dgc$rgsw_norm = 0
  dgc$grpID = grpID
  dgc$clone_size = n
  dgc$richness <- n_unq
  dgc$type = "limited"
  dgc$wmax = 0
  dgc$beta1 = 0
  dgc$clonotypic_entropy_sim = 0
  dgc$clonotypic_entropy_sim_mnorm = 0
  dgc$clonotypic_entropy_sim_lnorm = 0
  dgc$clonotypic_entropy_sim_mlnorm = 0
  dgc$clonotypic_entropy <- 0
  dgc$clonotypic_entropy_mnorm <- 0
  dgc$clonotypic_entropy_lnorm <- 0
  dgc$clonotypic_entropy_mlnorm <- 0
  dgc$clonotypic_diversity <- 0
  dgc$clonotypic_diversity_sim <- 0

    ## return clone db with unique seq identifier
  db_gp$ind <- 0

    for (i in 1:n_unq) {
      #idCluster[ind_unq[[i]]] <- idCluster_unq[i]
      db_gp$ind[ind_unq[[i]]] <- i
    }



    ## zero out across discrete categories
    if (!is.null(discreteVar)) {
      if (similarity) {
        for (subset in unique(db_gp[[discreteVar]])){
          db_subset <- db_gp[db_gp[[discreteVar]] == subset, ]
          res <- process_subset(db_subset)
          for (i in res$db$subsetInd) {
            for (j in res$db$subsetInd) {
              ii = res$db$ind[res$db$subsetInd==i]
              jj = res$db$ind[res$db$subsetInd==j]
              sim_mtx[ii,jj] = res$mtx[i, j]
            }
          }
        }
      aff_mtx <- sim_mtx
      } else{
      cmat = matrix(0, nrow=n_unq, ncol=n_unq)
      for (i in 1:n_unq) {
        dvars = db_gp[[discreteVar]][db_gp[["ind"]]==i]
        for (j in 1:n_unq) {
          cmat[i,j] = as.numeric( all( db_gp[[discreteVar]][db_gp[["ind"]]==j] %in% dvars))
        }
      }
      diag(cmat) = 1
      aff_mtx = cmat
      }
    }


    dbj = bcrCounts(db_gp, inds = "ind")
    # prob_mat =  aff_mtx
    # prob_mat[] <- 0
    #
    # for (i in 1:nrow(dbj)) {
    #   for (j in 1:nrow(dbj)) {
    #     prob_mat[i, j] = dbj$p[i] * dbj$p[j]
    #   }
    # }

    dbjp = bcrCounts_pheno(db_gp, inds = "ind", pheno=phenotype_var)

    dbj$w = 0
    dbj$wn = 0
    dbj$wnv = 0
    db_gp$w = 0
    db_gp$wn = 0
    dbjp$w = 0
    dbjp$wn = 0


    kdmatrix = 1 - aff_mtx

    for (i in dbj$ind) {
      #dbj$w[dbj$ind==i] = sum(aff_mtx[i, ]) # sum of affinities for each cell
      #dbj$wn[dbj$ind==i] = sum(aff_mtx[i, ])/sum(aff_mtx) # s
      dbj$w[dbj$ind==i] = sum(aff_mtx[i, ])  # sum of affinities for each cell
      dbj$wn[dbj$ind==i] = sum(aff_mtx[i, ]) * nrow(dbj) # sum of affinities for each cell * richness

      dbjp$w[dbjp$ind==i] = sum(aff_mtx[i, ])
      dbjp$wn[dbjp$ind==i] = sum(aff_mtx[i, ]) * nrow(dbjp)
      db_gp$w[db_gp$ind == i] = sum(aff_mtx[i, ])  # sum of affinities for each cell
      db_gp$wn[db_gp$ind == i] = sum(aff_mtx[i, ]) * nrow(dbj) # sum of affinities for each cell
      #db_gp$wn[db_gp$ind == i] = sum(aff_mtx[i, ]) / sum(aff_mtx)
    }


    wijmat = matrix(0, nrow = nrow(dbj), ncol = nrow(dbj))


    dbp =  get_jd(db_gp, pheno = phenotype_var,indVar = indVar)
    dpp =  get_jd_p(db_gp, pheno = phenotype_var,indVar = indVar)
    #dbp$wn <- dbp$w / sum(dbp$w)
    #
    dbp = db_gp %>% dplyr::group_by(.data[[indVar]], .data[["w"]],  .data[["wn"]], .data[[phenotype_var]]) %>%
      dplyr::summarise(n = n()) %>%
      tidyr::spread(key = {{phenotype_var}}, value = n, fill=0)



    jdmat <-  db_gp %>% dplyr::group_by(.data[[indVar]], .data[[phenotype_var]]) %>%
      dplyr::summarise(n = n()) %>%
      tidyr::spread(key = {{phenotype_var}}, value = n, fill=0) %>%
      dplyr::ungroup() %>%
      dplyr::select(-.data[[indVar]]) %>% as.matrix()


    # regw <- weighted_rich_gini_simpson_affinity_pairs(jdmat,
    #                                                   sequence_weights = kdmatrix,
    #                                                   #sequence_weights = disim_mtx,
    #                                                   affinity_weights = dbp$w,
    #                                                   #useRichness= TRUE,
    #                                                   #normalize_phenos = TRUE,
    #                                                   pheno_weights = NULL,
    #                                                   zero_handling = "ignore")
    #
    #
    #
    # rgw <- weighted_rich_gini_simpson_affinity(jdmat,
    #                                            affinity_weights = dbp$w,
    #                                            #useRichness= TRUE,
    #                                            #normalize_phenos = TRUE,
    #                                            #pheno_weights = NULL,
    #                                            zero_handling = "ignore")




    dbp_p = dbp
    null_mtx =  aff_mtx
    null_mtx[] <- 0
    diag(null_mtx) <- 1


    #jdmatn = normalize_columns(jdmat)
    #
    #     for (f in unique(db_gp[[phenotype_var]])) {
    #       p = dbp[[f]] / sum(dbp[[f]])
    #       ent <- similarity_sensitive_entropy(probabilities =p,
    #                                          similarity_matrix = aff_mtx,
    #                                          base = log_base,
    #                                          normalize_similarity = FALSE)
    #       dgc$clonotypic_entropy_sim[dgc$pheno==f] = ent
    #       dgc$clonotypic_entropy_sim_norm[dgc$pheno==f] = ent / logf(length(p), base=log_base)
    #     }
    #
    #

    entropies <- numeric(ncol(jdmat))
    max_entropies <- numeric(ncol(jdmat))
    normalized_entropies <- numeric(ncol(jdmat))
    diversities <- numeric(ncol(jdmat))
    normalized_diversities <- numeric(ncol(jdmat))

    null_entropies <- numeric(ncol(jdmat))
    null_max_entropies <- numeric(ncol(jdmat))
    null_normalized_entropies <- numeric(ncol(jdmat))
    null_diversities <- numeric(ncol(jdmat))
    null_normalized_diversities <- numeric(ncol(jdmat))

    probs_matrix <- normalize_columns(jdmat)
    totp = rowSums(jdmat)
    totP = totp / sum(totp)


    for (i in 1:ncol(probs_matrix)) {
      cname = colnames(probs_matrix)[i]
      tryCatch({
        result <- similarity_sensitive_entropy(probs_matrix[, i], aff_mtx)
        entropies[i] <- result$entropy
        max_entropies[i] <- result$max_entropy
        normalized_entropies[i] <- result$normalized_entropy
        diversities[i] <- result$diversity
        normalized_diversities[i] <- result$normalized_diversity

        resultn <- similarity_sensitive_entropy(probs_matrix[, i], null_mtx)
        null_entropies[i] <- resultn$entropy
        null_max_entropies[i] <- resultn$max_entropy
        null_normalized_entropies[i] <- resultn$normalized_entropy
        null_diversities[i] <- resultn$diversity
        null_normalized_diversities[i] <- resultn$normalized_diversity

      }, error = function(e) {
        print(paste("Error in Shannon entropy calculation for phenotype:", cname))
        entropies[i] <- NA
        max_entropies[i] <- NA
        normalized_entropies[i] <- NA
        diversities[i] <- NA
        normalized_diversities[i] <- NA
      })
    }

    #cat("\nEntropy values:\n")
    entropy_df <- data.frame(
      Distribution = colnames(probs_matrix),
      Entropy = entropies,
      Max_Entropy = max_entropies,
      Normalized_Entropy = normalized_entropies,
      Normalized_Diversity = normalized_diversities,
      Diversity = diversities,
      naive_Entropy = null_entropies,
      naive_Max_Entropy = null_max_entropies,
      naive_Normalized_Entropy = null_normalized_entropies,
      naive_Normalized_Diversity = null_normalized_diversities,
      naive_Diversity = null_diversities
    )
    entropy_df$n = nrow(dbp)
    entropy_df$grpID = grpID




    ## add results to dgc
    for (f in colnames(jdmat)) {
      dgc$clonotypic_entropy_sim[dgc$pheno==f] = entropy_df$Entropy[entropy_df$Distribution == f]
      dgc$clonotypic_entropy_sim_mnorm[dgc$pheno==f] = entropy_df$Normalized_Entropy[entropy_df$Distribution == f]
      dgc$clonotypic_entropy_sim_lnorm[dgc$pheno==f] =  entropy_df$Entropy[entropy_df$Distribution == f] / logf(nrow(dbp), base=log_base)
      dgc$clonotypic_entropy_sim_mlnorm[dgc$pheno==f] =  entropy_df$Normalized_Entropy[entropy_df$Distribution == f] / logf(nrow(dbp), base=log_base)
      dgc$clonotypic_diversity_sim[dgc$pheno==f] =  entropy_df$Normalized_Diversity[entropy_df$Distribution == f]
    }




    probs_matrixT <- cbind(totP, probs_matrix)
    colnames(probs_matrixT)[1] = "Mixed"
    # xentropy = similarity_sensitive_cross_entropy(
    #   probs_matrixT,
    #   aff_mtx,
    #   reference_distribution = 1,  # Mixed is the second column
    #   distribution_names = colnames(probs_matrixT)
    # )

    rentropy_sim = similarity_sensitive_relative_entropy(
      probs_matrixT,
      aff_mtx,symmetric = FALSE,return_cross_entropy = TRUE,
      reference_distribution = 1,  # Mixed is the second column
      distribution_names = colnames(probs_matrixT)
    )


    rentropy = similarity_sensitive_relative_entropy(
      probs_matrixT,
      null_mtx,
      reference_distribution = 1,  # Mixed is the second column
      distribution_names = colnames(probs_matrixT)
    )

    rentropy_sim_df = as.data.frame(rentropy_sim)
    rentropy_sim_df$phenotype = rownames(rentropy_sim_df)
    rentropy_sim_df$grpID = grpID

    rentropy_df = as.data.frame(rentropy)
    colnames(rentropy_df) =  paste0(colnames(rentropy_df), "_null")
    rentropy = cbind(rentropy_df, rentropy_sim_df)
    rentropy$n = nrow(dbp)






    ###proportion private to phenotype
    for (f in unique(db_gp[[phenotype_var]])) {
      dbp_p[[f]] = dbp_p[[f]] / sum(dbp_p[[f]])
    }
    ###

    for (f in unique(db_gp[[phenotype_var]])) {
      rgslist=list()
      wlist = list()
      #dlist = list()
      #dwlist = list()
      ix = dbp_p[[indVar]]
      if (sum(dbp_p[[f]]) == 0) {
        next
      }

      for (i in ix) {
        #jx = setdiff(ix, i)
        wn = dbp_p$wn[i]
        #d = dbp_p$d[i]
        #dw = dbp_p$dw[i]
        #pj = sum(dbp_p[[f]][jx])
        rgslist[i] =  dbp_p[[f]][i] * (1-dbp_p[[f]][i]) * wn
        wlist[i] = wn
        #dlist[i] =  dbp_p[[f]][i] * (1-dbp_p[[f]][i]) * d
        # dwlist[i] =  dbp_p[[f]][i] * (1-dbp_p[[f]][i]) * dw
      }

      if (sum(unlist(rgslist)) == 0) {
        next
      }

      dgc$rgsw[dgc$pheno==f] =  sum(unlist(rgslist))
      dgc$wmax[dgc$pheno==f] = max(unlist(wlist))
    }

    dgc$beta1 = dgc$wmax * (1 - (1/n_unq))
    dgc$rgsw_norm = dgc$rgsw / dgc$beta1


    return_list <- list("affinity_mat" = aff_mtx,
                        "db_clone" = db_gp,
                        "jd" = dbp,
                      #  "weighted_RGS_pairs" =  regw,
                       # "weighted_RGS" = rgw,
                        "db_pheno"= dgc,
                        "rel_entropies" = rentropy,
                        "marginal_entropies" = entropy_df
    )



    #setDT(dgc)
    #dgc <- dgc[rgsw >0,]
    return(return_list)
}






