
#' Takes a db, a cloneID, and the name of a phenotype variable and returns the affinity matrix, db, and data.frame of per-phenotype diversity metrics for that clone
#'
#' @param db db
#' @param cloneID ID of clone to analyze
#' @param phenotype_var phenotype variable
#' @param cell_id cell id
#' @param clone column name of clone variable in db
#' @param log_base base of log to use for shannon entropy calculations
#' @export
#' @returns data.frame of diversity metrics and phenotype ##list with affinity matrix, db for clone, and data.frame of per-phenotype diversity metrics using Simposon diversity
functional_diversity <- function(db, groupID=NULL, phenotype_var="subset", phenotype_reference=NULL,  cell_id=NULL, similarity=TRUE,
                               group = "subject_id", cdr3=FALSE, useAffinityWeights=TRUE,qs=0:2,
                               log_base=exp(1), distanceCutoff=FALSE, discreteVar="clone_id", nboot=100, subsample=NULL) {
  model = "spectral"
  method = "vj"
  linkage = c("single", "average", "complete")
  normalize = "len" ## c("len", "none"),
  germline = "germline_alignment"
  sequence = "sequence_alignment"
  junction = "junction"
  v_call = "v_call"
  j_call = "j_call"
  fields = NULL
  locus = "locus"
  only_heavy = TRUE
  split_light = FALSE
  targeting_model = shazam::HH_S5F
  len_limit = NULL
  first = FALSE
  #cdr3 = FALSE
  mod3 = FALSE
  max_n = 0
  threshold = 1
  base_sim = 0.95
  iter_max = 1000
  nstart = 1000
  nproc = 4
  verbose = FALSE
  log = NULL
  summarize_clones = FALSE
  indVar = "ind"

  # get clone
  print(groupID)

  db_clone <- as.data.frame(db[db[[group]] == groupID, ])

  if(!is.null(subsample)){
    if(nrow(db_clone) > subsample){
      cat("Subsampling ", nrow(db_clone), " cells to ", subsample, " cells... \n")
      ix <- sample(1:nrow(db_clone), size=subsample)
      db_clone <- db_clone[ix,]
    }
  }

  results_prep = prepare_clone(db = db_clone,
                               junction = junction, v_call = v_call, j_call = j_call,
                               first = first, cdr3 = cdr3, fields = fields,
                               cell_id = cell_id, locus = locus, only_heavy = only_heavy,
                               mod3 = mod3, max_n = max_n)
  dbfull = data.table::copy(db)
  db <- results_prep$db
  n_rmv_mod3 <- results_prep$n_rmv_mod3
  n_rmv_cdr3 <- results_prep$n_rmv_cdr3
  n_rmv_N <- results_prep$n_rmv_N
  junction_l <- results_prep$junction_l
  cdr3_col <-  results_prep$cdr3_col

  db_l <- db[db[[locus]] %in% c("IGK", "IGL", "TRA", "TRG"), , drop=F]
  db <- db[db[[locus]] %in% c("IGH", "TRB", "TRD"), , drop=F]
  db_gp <- db

  mutabs <- shazam::HH_S5F@mutability
  # Generated by using Rcpp::compileAttributes() -> do not edit by hand
  # Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

  #Rcpp::sourceCpp("~/Projects/code/scratch/scoper/src/RcppMutation.cpp") # scoper/src/RcppMutation.cpp")
  #Rcpp::sourceCpp("./src/RcppMutation.cpp")

  n <- nrow(db_gp)


  germs <- db_gp[[germline]]
  seqs <- db_gp[[sequence]]
  ## accomdate different length sequences for hamming distance
  juncs <- db_gp[[ifelse(cdr3, cdr3_col, junction)]]
  #juncs <- as.character( set_eq_seqDistance(juncs))
  junc_length <- unique(stringi::stri_length(juncs))
  if (length(junc_length) > 1) {
    juncs <- as.character( set_eq_seqDistance(juncs))
    junc_length <- unique(stringi::stri_length(juncs))
  }


  #juncs <- as.character( set_eq_seqDistance(juncs))
  # find unique seqs
  #.I = NULL
  seqs <- paste(seqs, juncs, germs, sep = "|")
  df <- data.table::as.data.table(seqs)[, list(list(.I)), by=seqs] %>%
    tidyr::separate(col = seqs, into = c("seqs_unq", "juncs_unq", "germs_unq"), sep = "\\|")
  n_unq <- nrow(df)
  ind_unq <- df$V1

  ## make result df here
  dgc = data.frame(pheno = unique(db_gp[[phenotype_var]]))
  dgc[[phenotype_var]] = unique(db_gp[[phenotype_var]])
  #dgc[[phenotype_var]] = unique(db_gp[[phenotype_var]])
  dgc$rgsw = 0
  dgc$rgsw_norm = 0
  dgc$clone_id = groupID
  dgc$clone_size = n
  dgc$richness <- n_unq
  dgc$type = "limited"
  dgc$wmax = 0
  dgc$beta1 = 0
  dgc$clonotypic_entropy_sim = 0
  dgc$clonotypic_entropy_sim_mnorm = 0
  dgc$clonotypic_entropy_sim_lnorm = 0
  dgc$clonotypic_entropy_sim_mlnorm = 0
  dgc$clonotypic_entropy <- 0
  dgc$clonotypic_entropy_mnorm <- 0
  dgc$clonotypic_entropy_lnorm <- 0
  dgc$clonotypic_entropy_mlnorm <- 0
  dgc$clonotypic_diversity <- 0
  dgc$clonotypic_diversity_sim <- 0



  if (n_unq <= 2) {

    return(dgc)


    return_list <- list("affinity_mat" = NULL,
                        "disim_mtx" = NULL,
                        "db_clone" = NULL,
                        "jd" = NULL,
                        "weighted_GS" =  NULL,
                        "db_pheno"= dgc)

    return(return_list)

  } else{
    dgc$type = "full"

    # find corresponding unique germs and junctions
    seqs_unq <- df$seqs_unq
    germs_unq <- df$germs_unq
    juncs_unq <- df$juncs_unq
    cat("Calculating distance matrix...\n")
    # calculate unique junctions distance matrix
    dist_mtx <- alakazam::pairwiseDist(seq = juncs_unq,
                                       dist_mat = getDNAMatrix(gap = 0))
    # count mutations from unique sequence imgt
    results <- pairwiseMutions(germ_imgt = germs_unq,
                               seq_imgt = seqs_unq,
                               junc_length = junc_length,
                               len_limit = len_limit,
                               cdr3 = cdr3,
                               mutabs = mutabs)
    tot_mtx <- results$pairWiseTotalMut
    sh_mtx <- results$pairWiseSharedMut
    mutab_mtx <- results$pairWiseMutability
    # calculate likelihhod matrix
    lkl_mtx <- likelihoods(tot_mtx = tot_mtx,
                           sh_mtx = sh_mtx,
                           mutab_mtx = mutab_mtx)
    # calculate weighted matrix
    disim_mtx <- dist_mtx * (1.0 - lkl_mtx)


    mtx = disim_mtx

    nearest_dist <- apply(mtx, 2,  function(x) {
      gt0 <- which(x > 0)
      if (length(gt0) != 0) { min(x[gt0]) } else { NA }
    })


    krnl_mtx <- krnlMtxGenerator(mtx = mtx)


    if (distanceCutoff) {
      aff_mtx <- makeAffinity(mtx_o = mtx,
                              mtx_k = krnl_mtx,
                              thd = max(nearest_dist, na.rm = T))
      #aff_mtx[aff_mtx > max(nearest_dist, na.rm = T)] <- 0
    } else {
      aff_mtx <- krnl_mtx
    }

    ## allow cutoff using a user supplied variable\

    ### use only for global
    # aff_mtx <- makeAffinity(mtx_o = mtx,
    #                       mtx_k = krnl_mtx,
    #                      thd = max(nearest_dist, na.rm = T))



    threshold = NULL
    base_sim = 0.95
    iter_max = 1000
    nstart = 1000
    #{
    ### constants
    n <- nrow(mtx)
    bs <- (1 - base_sim)*junc_length
    off_diags_nuq <- unique(mtx[row(mtx) != col(mtx)])


    #aff_mtx <- krnl_mtx

    aff_mtx[is.na(aff_mtx)] <- 0

    ## return clone db with unique seq identifier
    db_gp$ind <- 0

    for (i in 1:n_unq) {
      #idCluster[ind_unq[[i]]] <- idCluster_unq[i]
      db_gp$ind[ind_unq[[i]]] <- i
    }


    ## option to zero out across discrete categories
    if (!is.null(discreteVar)) {
      cids = list()
      for (i in 1:n_unq) {
        cids[[i]] = db_gp[[discreteVar]][db_gp[["ind"]]==i][1]

      }


      cids <- unlist(cids)
      cmat = outer(cids , cids, "==")
      mode(cmat) = "numeric"

      d_mtx = aff_mtx * cmat
    } else {
      null_mtx =  aff_mtx
      null_mtx[] <- 0
      diag(null_mtx) <- 1
      d_mtx <- null_mtx
      cmat <- null_mtx
    }


    if (!similarity){
      aff_mtx = d_mtx
    }




    dbj = bcrCounts(db_gp, inds = "ind")
    # prob_mat =  aff_mtx
    # prob_mat[] <- 0
    #
    # for (i in 1:nrow(dbj)) {
    #   for (j in 1:nrow(dbj)) {
    #     prob_mat[i, j] = dbj$p[i] * dbj$p[j]
    #   }
    # }

    dbjp = bcrCounts_pheno(db_gp, inds = "ind", pheno=phenotype_var)

    dbj$w = 0
    dbj$wn = 0
    dbj$wnv = 0
    db_gp$w = 0
    db_gp$wn = 0
    dbjp$w = 0
    dbjp$wn = 0


    kdmatrix = 1 - aff_mtx

    for (i in dbj$ind) {
      #dbj$w[dbj$ind==i] = sum(aff_mtx[i, ]) # sum of affinities for each cell
      #dbj$wn[dbj$ind==i] = sum(aff_mtx[i, ])/sum(aff_mtx) # s
      dbj$w[dbj$ind==i] = sum(aff_mtx[i, ])  # sum of affinities for each cell
      dbj$wn[dbj$ind==i] = sum(aff_mtx[i, ]) * nrow(dbj) # sum of affinities for each cell * richness

      dbjp$w[dbjp$ind==i] = sum(aff_mtx[i, ])
      dbjp$wn[dbjp$ind==i] = sum(aff_mtx[i, ]) * nrow(dbjp)
      db_gp$w[db_gp$ind == i] = sum(aff_mtx[i, ])  # sum of affinities for each cell
      db_gp$wn[db_gp$ind == i] = sum(aff_mtx[i, ]) * nrow(dbj) # sum of affinities for each cell
      #db_gp$wn[db_gp$ind == i] = sum(aff_mtx[i, ]) / sum(aff_mtx)
    }


    wijmat = matrix(0, nrow = nrow(dbj), ncol = nrow(dbj))


    dbp =  get_jd(db_gp, pheno = phenotype_var,indVar = indVar)
    dpp =  get_jd_p(db_gp, pheno = phenotype_var,indVar = indVar)
    #dbp$wn <- dbp$w / sum(dbp$w)
    #
    dbp = db_gp %>% dplyr::group_by(.data[[indVar]], .data[["w"]],  .data[["wn"]], .data[[phenotype_var]]) %>%
      dplyr::summarise(n = n()) %>%
      tidyr::spread(key = {{phenotype_var}}, value = n, fill=0)



    jdmat <-  db_gp %>% dplyr::group_by(.data[[indVar]], .data[[phenotype_var]]) %>%
      dplyr::summarise(n = n()) %>%
      tidyr::spread(key = {{phenotype_var}}, value = n, fill=0) %>%
      dplyr::ungroup() %>%
      dplyr::select(-.data[[indVar]]) %>% as.matrix()

    jdmat_c <- db_gp %>% dplyr::group_by(.data[[discreteVar]],  .data[[phenotype_var]]) %>%
      dplyr::summarise(n = n()) %>%
      tidyr::spread(key = {{phenotype_var}}, value = n, fill=0) %>%
      dplyr::ungroup() %>%
      dplyr::select(-.data[[discreteVar]]) %>% as.matrix()


    # cat("calculating simpson diversities...\n")

    # regw <- weighted_rich_gini_simpson_affinity_pairs(jdmat,
    #                                                   sequence_weights = kdmatrix,
    #                                                   #sequence_weights = disim_mtx,
    #                                                   affinity_weights = dbp$w,
    #                                                   #useRichness= TRUE,
    #                                                   #normalize_phenos = TRUE,
    #                                                   pheno_weights = NULL,
    #                                                   zero_handling = "ignore")
    #
    #
    #
    # rgw <- weighted_rich_gini_simpson_affinity(jdmat,
    #                                            affinity_weights = dbp$w,
    #                                            #useRichness= TRUE,
    #                                            #normalize_phenos = TRUE,
    #                                            #pheno_weights = NULL,
    #                                            zero_handling = "ignore")
    #
    # rgw$groupID = groupID
    # regw$groupID = groupID
    #



    dbp_p = dbp

    ###proportion private to phenotype
    for (f in unique(db_gp[[phenotype_var]])) {
      dbp_p[[f]] = dbp_p[[f]] / sum(dbp_p[[f]])
    }
    ###

    for (f in unique(db_gp[[phenotype_var]])) {
      rgslist=list()
      wlist = list()
      #dlist = list()
      #dwlist = list()
      ix = dbp_p[[indVar]]
      if (sum(dbp_p[[f]]) == 0) {
        next
      }

      for (i in ix) {
        #jx = setdiff(ix, i)
        wn = dbp_p$wn[i]
        #d = dbp_p$d[i]
        #dw = dbp_p$dw[i]
        #pj = sum(dbp_p[[f]][jx])
        rgslist[i] =  dbp_p[[f]][i] * (1-dbp_p[[f]][i]) * wn
        wlist[i] = wn
        #dlist[i] =  dbp_p[[f]][i] * (1-dbp_p[[f]][i]) * d
        # dwlist[i] =  dbp_p[[f]][i] * (1-dbp_p[[f]][i]) * dw
      }

      if (sum(unlist(rgslist)) == 0) {
        next
      }

      dgc$rgsw[dgc$pheno==f] =  sum(unlist(rgslist))
      dgc$wmax[dgc$pheno==f] = max(unlist(wlist))
    }

    dgc$beta1 = dgc$wmax * (1 - (1/n_unq))
    dgc$rgsw_norm = dgc$rgsw / dgc$beta1


    #jdmatn = normalize_columns(jdmat)
    #
    #     for (f in unique(db_gp[[phenotype_var]])) {
    #       p = dbp[[f]] / sum(dbp[[f]])
    #       ent <- similarity_sensitive_entropy(probabilities =p,
    #                                          similarity_matrix = aff_mtx,
    #                                          base = log_base,
    #                                          normalize_similarity = FALSE)
    #       dgc$clonotypic_entropy_sim[dgc$pheno==f] = ent
    #       dgc$clonotypic_entropy_sim_norm[dgc$pheno==f] = ent / logf(length(p), base=log_base)
    #     }
    #
    #
    cat("calculating entropies...")

#
#     entropies <- numeric(ncol(jdmat))
#     max_entropies <- numeric(ncol(jdmat))
#     normalized_entropies <- numeric(ncol(jdmat))
#     diversities <- numeric(ncol(jdmat))
#     normalized_diversities <- numeric(ncol(jdmat))
#
#     null_entropies <- numeric(ncol(jdmat))
#     null_max_entropies <- numeric(ncol(jdmat))
#     null_normalized_entropies <- numeric(ncol(jdmat))
#     null_diversities <- numeric(ncol(jdmat))
#     null_normalized_diversities <- numeric(ncol(jdmat))
#
#     disc_entropies <- numeric(ncol(jdmat))
#     disc_max_entropies <- numeric(ncol(jdmat))
#     disc_normalized_entropies <- numeric(ncol(jdmat))
#     disc_diversities <- numeric(ncol(jdmat))
#     disc_normalized_diversities <- numeric(ncol(jdmat))
#
     probs_matrix <- normalize_columns(jdmat)
     totp = rowSums(jdmat)
     totP = totp / sum(totp)
     cell_n = colSums(jdmat)

    #
    #     for (i in 1:ncol(probs_matrix)) {
    #       cname = colnames(probs_matrix)[i]
    #       tryCatch({
    #       result <- similarity_sensitive_entropy(probs_matrix[, i], aff_mtx, base = log_base, computeMax = computeMax)
    #       entropies[i] <- result$entropy
    #       max_entropies[i] <- result$max_entropy
    #       normalized_entropies[i] <- result$normalized_entropy
    #       diversities[i] <- result$diversity
    #       normalized_diversities[i] <- result$normalized_diversity
    #
    #       resultn <- similarity_sensitive_entropy(probs_matrix[, i], cmat, base=log_base,  computeMax = computeMax)
    #       null_entropies[i] <- resultn$entropy
    #       null_max_entropies[i] <- resultn$max_entropy
    #       null_normalized_entropies[i] <- resultn$normalized_entropy
    #       null_diversities[i] <- resultn$diversity
    #       null_normalized_diversities[i] <- resultn$normalized_diversity
    #
    #       resultd <- similarity_sensitive_entropy(probs_matrix[, i], d_mtx, base=log_base,  computeMax = computeMax)
    #       disc_entropies[i] <- resultd$entropy
    #       disc_max_entropies[i] <- resultd$max_entropy
    #       disc_normalized_entropies[i] <- resultd$normalized_entropy
    #       disc_diversities[i] <- resultd$diversity
    #       disc_normalized_diversities[i] <- resultd$normalized_diversity
    #
    #     }, error = function(e) {
    #         print(paste("Error in Shannon entropy calculation for phenotype:", cname))
    #         entropies[i] <- NA
    #         max_entropies[i] <- NA
    #         normalized_entropies[i] <- NA
    #         diversities[i] <- NA
    #         normalized_diversities[i] <- NA
    #       })
    #     }
    #
    #     #cat("\nEntropy values:\n")
    #     entropy_df <- data.frame(
    #       Distribution = colnames(probs_matrix),
    #       Entropy = entropies,
    #       Max_Entropy = max_entropies,
    #       Normalized_Entropy = normalized_entropies,
    #       Normalized_Diversity = normalized_diversities,
    #       Diversity = diversities,
    #       naive_Entropy = null_entropies,
    #       naive_Max_Entropy = null_max_entropies,
    #       naive_Normalized_Entropy = null_normalized_entropies,
    #       naive_Normalized_Diversity = null_normalized_diversities,
    #       naive_Diversity = null_diversities,
    #       isim_Entropy = disc_entropies,
    #       isim_Max_Entropy = disc_max_entropies,
    #       isim_Normalized_Entropy = disc_normalized_entropies,
    #       isim_Normalized_Diversity = disc_normalized_diversities,
    #       isim_Diversity = disc_diversities,
    #       cell_n = cell_n
    #     )
    #     entropy_df$n = nrow(dbp)
    #     entropy_df$groupID = groupID
    #
    #
    #
    #
    # ## add results to dgc
    #     for (f in colnames(jdmat)) {
    #         dgc$clonotypic_entropy_sim[dgc$pheno==f] = entropy_df$Entropy[entropy_df$Distribution == f]
    #         dgc$clonotypic_entropy_sim_mnorm[dgc$pheno==f] = entropy_df$Normalized_Entropy[entropy_df$Distribution == f]
    #         dgc$clonotypic_entropy_sim_lnorm[dgc$pheno==f] =  entropy_df$Entropy[entropy_df$Distribution == f] / logf(nrow(dbp), base=log_base)
    #         dgc$clonotypic_entropy_sim_mlnorm[dgc$pheno==f] =  entropy_df$Normalized_Entropy[entropy_df$Distribution == f] / logf(nrow(dbp), base=log_base)
    #         dgc$clonotypic_diversity_sim[dgc$pheno==f] =  entropy_df$Normalized_Diversity[entropy_df$Distribution == f]
    #       }
    #



    probs_matrixT <- cbind(totP, probs_matrix)
    colnames(probs_matrixT)[1] = "Mixed"
    # xentropy = similarity_sensitive_cross_entropy(
    #   probs_matrixT,
    #   aff_mtx,
    #   reference_distribution = 1,  # Mixed is the second column
    #   distribution_names = colnames(probs_matrixT)
    # )

    # if (!is.null(phenotype_reference)) {
    #   refindex = which(colnames(probs_matrixT) == phenotype_reference)
    # } else {
    #   refindex = NULL
    # }
    #
    # rentropy_sim = similarity_sensitive_relative_entropy(
    #   probs_matrixT,
    #   aff_mtx,symmetric = FALSE,return_cross_entropy = TRUE,base = log_base,
    #   reference_distribution = refindex,  # Mixed is the second column
    #   distribution_names = colnames(probs_matrixT)
    # )
    #
    # rentropy_naive = similarity_sensitive_relative_entropy(
    #   probs_matrixT,
    #   cmat,symmetric = FALSE,return_cross_entropy = TRUE, base = log_base,
    #   reference_distribution = refindex,  # Mixed is the second column
    #   distribution_names = colnames(probs_matrixT)
    # )
    #
    #
    # rentropy_isim = similarity_sensitive_relative_entropy(
    #   probs_matrixT,
    #   d_mtx, base = log_base, symmetric = FALSE,return_cross_entropy = TRUE,
    #   reference_distribution = refindex,  # Mixed is the second column
    #   distribution_names = colnames(probs_matrixT)
    # )
    #
    # rentropy_sim_df = as.data.frame(rentropy_sim$relative_entropy)
    # rentropy_sim_df$phenotype = rownames(rentropy_sim_df)
    # rentropy_sim_df$groupID = groupID
    #
    # rentropy_df = as.data.frame(rentropy_isim$relative_entropy)
    # colnames(rentropy_df) =  paste0(colnames(rentropy_df), "_intra_sim")
    #
    # rentropy_naive_df = as.data.frame(rentropy_naive$relative_entropy)
    # colnames(rentropy_naive_df) =  paste0(colnames(rentropy_naive_df), "_discrete")
    #
    #
    # rentropy = cbind(rentropy_sim_df, rentropy_df)
    # rentropy = cbind(rentropy, rentropy_naive_df)
    # rentropy$n <- nrow(dbp)
    # rentropy$ncells <- c(sum(totp), colSums(jdmat))
    #



    #qs = seq(0,2, by=.1)


    rownames(aff_mtx) <- paste0("cid_", dbp$ind)
    colnames(aff_mtx) <- rownames(aff_mtx)
    rownames(jdmat) <- paste0("cid_", dbp$ind)
    db_gp$cid <- paste0("cid_", db_gp$ind)


    ddf = computeDs(jdmat, aff_mtx, qs=qs)
    nmat <- aff_mtx
    nmat[] <- 0
    diag(nmat) <- 1
    ddf_n = computeDs(jdmat, aff_mat=NULL, qs=qs)
    ddf_i = computeDs(jdmat, aff_mat=d_mtx, qs=qs)

    ddf_clone <- computeDs(jdmat_c,aff_mat=NULL, qs=qs)
    ddf_n$sim = "naive"
    ddf_i$sim = "sim"
    ddf$sim = "global"
    ddf_clone$sim <- "clone"
    ddf_shuffle <- computeDs_shuffle(jdmat,aff_mtx, qs=qs)
    ddf_shuffle$sim <- "shuffle"

    ddf_boot = repartition_boot(jdmat = jdmat, aff_mat = aff_mtx, nboot = nboot, qs=qs)
    ddf_boot$groupID <- groupID


    ddfm <- computeMetaDs(jdmat, aff_mat=aff_mtx, qs=qs)
    ddfm$groupID <- groupID

    db_gp$cid <- paste0("cid_", db_gp$ind)
    db_gp$clone <- db_gp$cid
    bres <- makeBoot(db_gp, jdmat=jdmat, aff_mat=aff_mtx, group=phenotype_var, qs=qs, nboot=nboot, clone="cid", min_n=2, max_n=NULL)

    # bres_c <- makeBoot(db_gp, jdmat=jdmat, aff_mat=aff_mtx, group=phenotype_var, qs=qs, nboot=nboot, clone="cid", min_n=2, max_n=NULL)

    bres$groupID <- groupID
    ddf <- rbind(ddf, ddf_n, ddf_i, ddf_clone)
    ddf$groupID <- groupID



    cat("completed\n")

    return_list <- list("affinity_mat" = aff_mtx,
                        "disim_mtx" = disim_mtx,
                        "db_clone" = db_gp,
                        "jd" = dbp,
                        "P" = jdmat,
                        #"weighted_RGS_pairs" =  regw,
                        #"weighted_RGS" = rgw,
                        ##"db_pheno"= dgc,
                        #"rel_entropies" = rentropy,
                        #"marginal_entropies" = entropy_df,
                        "diversities" = ddf,
                        ##"diversities_corrected" = ddf_a,
                        "metaDiversities" = ddfm,
                        "diversity_shuffle" = ddf_boot,
                        "diversities_bootstrap" = bres
    )



    #setDT(dgc)
    #dgc <- dgc[rgsw >0,]
    return(return_list)
  }
}

#' Run functional_diversity using metadata stored in a Seurat object
#'
#' Extracts the cell-level metadata from a Seurat object, optionally remaps
#' column names to the defaults expected by `functional_diversity`, and then
#' forwards the augmented metadata to `functional_diversity`.
#'
#' @param seurat_obj A Seurat or SeuratObject containing the required metadata.
#' @param groupID Identifier (or identifiers) of the group in the column supplied via `group`.
#' @param phenotype_var Name of the metadata column describing phenotypes; passed to `functional_diversity`.
#' @param phenotype_reference Optional phenotype label to use as reference; passed to `functional_diversity`.
#' @param group Name of the metadata column describing the grouping variable; passed to `functional_diversity`.
#' @param column_map Named list mapping canonical column names used by `functional_diversity`
#'   (`clone_id`, `germline_alignment`, `sequence_alignment`, `junction`, `locus`) to the
#'   corresponding column names present in the Seurat metadata. Defaults assume metadata already
#'   uses the canonical names.
#' @param metadata Optional data.frame to use instead of extracting metadata from `seurat_obj`.
#' @param ... Additional arguments forwarded to `functional_diversity`.
#'
#' @return The result of calling `functional_diversity` on the extracted metadata.
#' @export
functional_diversity_from_seurat <- function(seurat_obj,
                                             groupID,
                                             phenotype_var = "subset",
                                             phenotype_reference = NULL,
                                             group = "subject_id",
                                             column_map = list(
                                               clone_id = "clone_id",
                                               germline_alignment = "germline_alignment",
                                               sequence_alignment = "sequence_alignment",
                                               junction = "junction",
                                               locus = "locus"
                                             ),
                                             metadata = NULL,
                                             ...) {

  dots <- list(...)

  if (!inherits(seurat_obj, c("Seurat", "SeuratObject"))) {
    stop("`seurat_obj` must inherit from `Seurat` or `SeuratObject`.")
  }

  if (is.null(metadata)) {
    metadata <- tryCatch(seurat_obj[[]], error = function(e) NULL)
    if (is.null(metadata)) {
      metadata <- tryCatch(seurat_obj@meta.data, error = function(e) NULL)
    }
  }

  if (is.null(metadata) || !is.data.frame(metadata)) {
    stop("Unable to extract metadata from `seurat_obj`; supply it via the `metadata` argument.")
  }

  db <- as.data.frame(metadata, stringsAsFactors = FALSE)

  required_map_names <- c("clone_id", "germline_alignment", "sequence_alignment", "junction", "locus")
  missing_map_names <- setdiff(required_map_names, names(column_map))
  if (length(missing_map_names) > 0) {
    stop("`column_map` must provide entries for: ", paste(missing_map_names, collapse = ", "), ".")
  }

  required_cols <- unique(c(group, phenotype_var, unlist(column_map)))
  missing_cols <- setdiff(required_cols, colnames(db))
  if (length(missing_cols) > 0) {
    stop("The following required metadata columns are missing: ", paste(missing_cols, collapse = ", "), ".")
  }

  for (canonical_name in names(column_map)) {
    source_col <- column_map[[canonical_name]]
    if (!identical(canonical_name, source_col) || !canonical_name %in% colnames(db)) {
      db[[canonical_name]] <- db[[source_col]]
    }
  }

  if (!"cell_id" %in% colnames(db)) {
    db$cell_id <- rownames(db)
  }

  if (is.null(groupID) && !"groupID" %in% names(dots)) {
    stop("`groupID` must be supplied to identify the group to analyse.")
  }

  default_args <- list(
    db = db,
    groupID = groupID,
    phenotype_var = phenotype_var,
    phenotype_reference = phenotype_reference,
    group = group
  )

  if (!"cell_id" %in% names(dots)) {
    default_args$cell_id <- "cell_id"
  }

  if (!"discreteVar" %in% names(dots) && "clone_id" %in% names(db)) {
    default_args$discreteVar <- "clone_id"
  }

  args <- utils::modifyList(default_args, dots)

  do.call(functional_diversity, args)
}

